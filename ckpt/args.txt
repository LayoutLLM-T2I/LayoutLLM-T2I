{
  "exp": "layoutt2i",
  "shot_number": 2,
  "seed": 53,
  "train_json_path": "../dataset/coco/annotations_processed/train2014_cap_ins.json",
  "feature_path": "./features/train_text_feats_clip_large.pt",
  "img_dir": "../dataset/coco/images/train2014",
  "sampled_data_dir": "./data",
  "train_number": 64,
  "cand_number": 32,
  "num_workers": 0,
  "engine": "gpt-3.5-turbo",
  "temperature": 0.0,
  "max_tokens": 512,
  "frequency_penalty": 0.0,
  "presence_penalty": 0.0,
  "gpu": "7",
  "model_config": "openai/clip-vit-large-patch14",
  "lr": 0.0005,
  "epochs": 10,
  "embedding_size": 128,
  "batch_size": 8,
  "policy_temperature": 1.0,
  "ckpt_root": "./checkpoints",
  "aesthetic_ckpt": "./checkpoints/aesthetic/sac+logos+ava1-l14-linearMSE.pth",
}
